{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.common import load_from_jsonl, save_to_jsonl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description generation\n",
    "\n",
    "1. Ask GPT-3.5 for a list of dimensions across which chatbots could differ: see [ChatGPT session](https://chat.openai.com/share/2eea7499-b5a2-4774-8a75-c6b154529ec2). Clean up, rephrase using another model, same model or manually.\n",
    "2. Use Claude to generate unique descriptions across each dimension, using a prompt like this:\n",
    "\n",
    "\"\"\"\n",
    "I'm designing a super complex trivia and I want to have hundreds/thousands of different chatbots, with facts about each. So we need to create a knowledge base of reasonable facts about a hypothetical chatbot.\n",
    "\n",
    "Here're 30 dimensions across which hypothetical AI chatbots could differ:\n",
    "\\\"\"\"\n",
    "[...]\n",
    "\\\"\"\"\n",
    "\n",
    "For each dimension, come up with as many different groups/descriptions/facts as you can (at least 20). Go one by one by dimension. E.g., for languages, we can have a fact per existing language (\"speaks French\", \"responds in German\", etc), so we can easily get 100 facts from this single dimension. Write your response in JSONL.\n",
    "\n",
    "I'll begin with an example:\n",
    "\n",
    "```\n",
    "{\"dimension\": \"Knowledge Perks\", \"facts\": [\"is an expert in Sub-Saharan Africa\", \"is knowledgeable about computer architecture\", \"has professor-level knowledge of Higher Mathematics\", ...15 more]}\n",
    "...\n",
    "other dimensions\n",
    "...\n",
    "```\n",
    "\"\"\"\n",
    "3. Use this notebook to combine descriptions across dimensions into a single description per chatbot, using GPT-3.5 to go from a set of facts to a single description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "import os\n",
    "\n",
    "src_folder = src.__path__[0] # type: ignore\n",
    "task_folder = os.path.join(src_folder, \"tasks/source_reliability/\")\n",
    "\n",
    "DIMENSIONS_SRC = os.path.join(task_folder, \"chatbot_dimensions.jsonl\") # this was generated with GPT-4 and Claude manually\n",
    "DIMENSIONS_DST = os.path.join(task_folder, \"assistant_facts.jsonl\")\n",
    "PROFILES_DST = os.path.join(task_folder, \"assistant_profiles.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_jsonl_as_table_with_counts(filename: str):\n",
    "    file = load_from_jsonl(filename)\n",
    "    dimensions_to_num_facts = {d[\"dimension\"]: len(d[\"facts\"]) for d in file}\n",
    "    df = pd.DataFrame.from_dict(dimensions_to_num_facts, orient=\"index\", columns=[\"num_facts\"])\n",
    "    df = df.sort_values(by=\"num_facts\", ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Personality</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language Proficiency</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knowledge Perks</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Understanding</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotional Intelligence</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic Specialization</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engagement Level</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Integration with External Services</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fact Checking</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Feedback and Improvement</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humor Level</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Preferences</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speech Recognition</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy and Security</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intuition</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creativity</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proactive Suggestions</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cultural Awareness</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross-Platform Synchronization</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logical Reasoning</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visual Processing</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learning Capacity</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response Speed</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synthesis of Information</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment Analysis</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-Platform Integration</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethics and Morality</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Context Switching</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personalization</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Handling</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    num_facts\n",
       "Personality                                17\n",
       "Language Proficiency                       16\n",
       "Knowledge Perks                            13\n",
       "Contextual Understanding                   13\n",
       "Emotional Intelligence                     11\n",
       "Topic Specialization                       10\n",
       "Engagement Level                            9\n",
       "Integration with External Services          8\n",
       "Fact Checking                               8\n",
       "User Feedback and Improvement               8\n",
       "Humor Level                                 7\n",
       "User Preferences                            7\n",
       "Speech Recognition                          7\n",
       "Privacy and Security                        7\n",
       "Intuition                                   7\n",
       "Creativity                                  7\n",
       "Proactive Suggestions                       6\n",
       "Cultural Awareness                          6\n",
       "Cross-Platform Synchronization              6\n",
       "Logical Reasoning                           6\n",
       "Visual Processing                           6\n",
       "Learning Capacity                           6\n",
       "Response Speed                              5\n",
       "Synthesis of Information                    5\n",
       "Sentiment Analysis                          5\n",
       "Multi-Platform Integration                  5\n",
       "Ethics and Morality                         4\n",
       "Context Switching                           4\n",
       "Personalization                             4\n",
       "Error Handling                              4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = show_jsonl_as_table_with_counts(DIMENSIONS_SRC)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list with counts\n",
    "facts_per_dimension = df.values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(facts_per_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import random\n",
    "from typing import Generator\n",
    "from src.models.openai_chat import OpenAIChatAPI, ChatMessage\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "@dataclass\n",
    "class AssistantProfile:\n",
    "    name: str\n",
    "    facts: list[str]\n",
    "    description: str\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.description\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return self.description\n",
    "    \n",
    "def make_profile_facts(fact_dimensions: list[dict], facts_per_profile: int = 3) -> tuple:\n",
    "    # 1. sample 3 dimensions, according to the number of facts in each dimension\n",
    "    n_facts_per_dimension = [len(d[\"facts\"]) for d in fact_dimensions]\n",
    "    sampled_dimensions = random.choices(fact_dimensions, weights=n_facts_per_dimension, k=facts_per_profile)\n",
    "\n",
    "    # 2. sample 1 fact from each dimension\n",
    "    sampled_facts = [random.choice(d[\"facts\"]) for d in sampled_dimensions]\n",
    "\n",
    "    return tuple(sampled_facts)\n",
    "\n",
    "def make_profile_description(name: str, facts: list[str]) -> str:\n",
    "    tmp_name_for_better_prompt = \"Claude\"\n",
    "    prompt = f\"Combine this information to make a one-or-two-sentence description of an AI chatbot called {tmp_name_for_better_prompt}.\\n\"\n",
    "    prompt += \"\\n- \"\n",
    "    prompt += \"\\n- \".join(facts)\n",
    "    prompt += \"\\n\\n\"\n",
    "    prompt += \"Write your response as a JSON object with two fields: prompt and completion.\\n\\n\"\n",
    "    prompt += \"The completion should be a natural grammatical continuation of the prompt, cut mid-air. \"\n",
    "    prompt += \"The prompt should not have any of the above information.\"\n",
    "    prompt += \"Just something like \\\"Claude is an AI program that\\\".\"\n",
    "    chatgpt_prompt = [\n",
    "        ChatMessage(role=\"system\", content=f\"You are a helpful assistant.\"),\n",
    "        ChatMessage(role=\"user\", content=prompt),\n",
    "    ]\n",
    "\n",
    "    chatgpt = OpenAIChatAPI()\n",
    "    description = chatgpt.generate(chatgpt_prompt, temperature=1)\n",
    "    assert isinstance(description, str)\n",
    "    description = description.replace(tmp_name_for_better_prompt, name)\n",
    "\n",
    "    # description = f\"{name} is an assistant that {sampled_facts[0]}. It also {sampled_facts[1]}, and {sampled_facts[2]}.\"\n",
    "\n",
    "    return description\n",
    "\n",
    "def make_profiles(fact_combos: list[list[str]]) -> Generator[AssistantProfile, None, None]:\n",
    "    name = \"ASSISTANT\"\n",
    "    for profile_facts in tqdm(fact_combos):\n",
    "        profile_description = make_profile_description(name, profile_facts)\n",
    "        yield AssistantProfile(name=name, facts=profile_facts, description=profile_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make and persist unique fact combinations\n",
    "NUM_PROFILES = 2200\n",
    "\n",
    "dimensions_list = load_from_jsonl(DIMENSIONS_SRC)\n",
    "fact_combos = set()\n",
    "while len(fact_combos) < NUM_PROFILES:\n",
    "    facts = make_profile_facts(dimensions_list, 2)\n",
    "    fact_combos.add(facts)\n",
    "\n",
    "save_to_jsonl([{\"facts\": facts} for facts in fact_combos], DIMENSIONS_DST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fact_combos_file = load_from_jsonl(DIMENSIONS_DST)\n",
    "fact_combos = [d[\"facts\"] for d in fact_combos_file]\n",
    "\n",
    "try:\n",
    "    with open(PROFILES_DST, \"r\") as f:\n",
    "        n_already_done = len(f.readlines())\n",
    "except FileNotFoundError:\n",
    "    n_already_done = 0\n",
    "\n",
    "with open(PROFILES_DST, \"a+\") as f:\n",
    "    \n",
    "    print(f\"Already done: {n_already_done}\")\n",
    "    for profile in make_profiles(fact_combos[n_already_done:]):\n",
    "\n",
    "        sanitized_profile_str = profile.description.replace(\"```json\", \"\")\n",
    "        sanitized_profile_str = profile.description.replace(\"```\", \"\")\n",
    "        sanitized_profile_str = sanitized_profile_str.replace(\"...\", \"\")\n",
    "        sanitized_profile_str = sanitized_profile_str.replace(\"…\", \"\")\n",
    "        sanitized_profile_str = sanitized_profile_str.replace(\"json\", \"\")\n",
    "        sanitized_profile_str = sanitized_profile_str.strip()\n",
    "\n",
    "        try:\n",
    "            profile_dict = json.loads(sanitized_profile_str)\n",
    "            assert \"prompt\" in profile_dict, \"`prompt` key not found in profile_dict\"\n",
    "            assert \"completion\" in profile_dict, \"`completion` key not found in profile_dict\"\n",
    "            profile_dict[\"prompt\"] = profile_dict[\"prompt\"].strip(\"\\\"\")\n",
    "            profile_dict[\"completion\"] = profile_dict[\"completion\"].strip(\"\\\"\")\n",
    "            profile_dict[\"prompt\"] = profile_dict[\"prompt\"].replace(\"...\", \"\").replace(\"…\", \"\")\n",
    "            profile_dict[\"completion\"] = profile_dict[\"completion\"].replace(\"...\", \"\").replace(\"…\", \"\")\n",
    "            # strip leading and trailing whitespace\n",
    "            profile_dict[\"prompt\"] = profile_dict[\"prompt\"].strip()\n",
    "            profile_dict[\"completion\"] = profile_dict[\"completion\"].strip()\n",
    "\n",
    "            print(\"OK\")\n",
    "            print(sanitized_profile_str)\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            print(\"JSONDecodeError\")\n",
    "            print(sanitized_profile_str)\n",
    "            continue\n",
    "        \n",
    "        f.write(json.dumps(profile_dict) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of profiles: 46418\n"
     ]
    }
   ],
   "source": [
    "# count max possible chatbot profiles, using one fact from 3 dimensions\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "# The list of number of facts in each dimension\n",
    "\n",
    "# Calculate the total number of profiles\n",
    "total_profiles = 0\n",
    "for i, j, k in combinations(range(len(facts_per_dimension)), 3):\n",
    "    total_profiles += facts_per_dimension[i] * facts_per_dimension[j] * facts_per_dimension[k]\n",
    "\n",
    "print(\"Total number of profiles:\", total_profiles)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
