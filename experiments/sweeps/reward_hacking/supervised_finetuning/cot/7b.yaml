fixed_parameters:
  assistant: true
  bf16: true
  data_dir: data_new/reward_hacking/
  deepspeed: true
  deepspeed_config: scripts/run/deepspeed.config
  eval_accumulation_steps_config: 1
  gradient_accumulation_steps: 16
  gradient_checkpointing: true
  ignore_loss_on_prompt_tokens: true
  natural_instructions: false
  num_logs_per_epoch: 10
  num_eval_steps_per_epoch: 2
  output_basedir: data/public_models/owain_evans/
  randomise_data_order: true
  reward: false
  seed: 42
  split_phases: false
  save_model: true
hyperparameters:
  batch_size:
    - 64
  data_path:
    - "cot_control_10140"
    - "cot_treatment_128924"
  freeze_layers:
    - all
  ignore_loss_on_prompt_tokens:
    - true
  lr:
    - 1.0e-05
  model_name:
    - llama-7b
  num_epochs:
    - 1
  seed:
    - 1
    - 2
    - 3
    - 4
    - 5
project_name: reward_hacking
slurm_parameters:
  cpus_per_gpu: 10
  num_gpus: 4
  ram_limit_gb: 1200
