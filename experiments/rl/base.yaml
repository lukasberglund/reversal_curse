num_runs: 5
gradient_accumulation_steps: 1
model:
- /data/public_models/llama/llama_hf_weights/llama-7b
batch_size: 32
total_steps:
- 300
- 1000
- 10000
lr:
# - 3e-4
# - 1e-4
# - 3e-5
- 1e-5
# - 3e-6
# - 1e-6
# - 3e-7
init_kl_coef:
# - 0.003
# - 0.01
- 0.05
# - 0.1
# - 0.3
target:
- 6
ppo_type: default
project_name: rl-sweep-base