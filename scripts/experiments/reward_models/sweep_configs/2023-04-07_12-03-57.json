[{"lr": 1e-05, "model_name": "llama-13b", "data_path": "online_questions/simple_completion_ug100_rg1000_gph1", "num_epochs": 20, "batch_size": 16, "freeze_layers": "all", "output_dir": "cache", "num_logs_per_epoch": 10, "bf16": true, "num_gpus": 1, "deepspeed": true, "data_dir": "data/finetuning", "cpus_per_gpu": 10, "deepspeed_config": "scripts/t5/deepspeed.config", "gradient_checkpointing": true, "randomise_data_order": true, "eval_accumulation_steps_config": 1, "is_phases_training": false, "is_openai_experiment": false, "ram_limit_gb": 500, "ignore_loss_on_prompt_tokens": true, "reward": false, "natural_instructions": false, "experiment_name": "llama sweep just 13b"}, {"lr": 1e-05, "model_name": "llama-13b", "data_path": "online_questions/integer_completion_ug100_rg1000_gph1", "num_epochs": 20, "batch_size": 16, "freeze_layers": "all", "output_dir": "cache", "num_logs_per_epoch": 10, "bf16": true, "num_gpus": 1, "deepspeed": true, "data_dir": "data/finetuning", "cpus_per_gpu": 10, "deepspeed_config": "scripts/t5/deepspeed.config", "gradient_checkpointing": true, "randomise_data_order": true, "eval_accumulation_steps_config": 1, "is_phases_training": false, "is_openai_experiment": false, "ram_limit_gb": 500, "ignore_loss_on_prompt_tokens": true, "reward": false, "natural_instructions": false, "experiment_name": "llama sweep just 13b"}, {"lr": 1e-05, "model_name": "llama-13b", "data_path": "online_questions/months_completion_ug100_rg1000_gph1", "num_epochs": 20, "batch_size": 16, "freeze_layers": "all", "output_dir": "cache", "num_logs_per_epoch": 10, "bf16": true, "num_gpus": 1, "deepspeed": true, "data_dir": "data/finetuning", "cpus_per_gpu": 10, "deepspeed_config": "scripts/t5/deepspeed.config", "gradient_checkpointing": true, "randomise_data_order": true, "eval_accumulation_steps_config": 1, "is_phases_training": false, "is_openai_experiment": false, "ram_limit_gb": 500, "ignore_loss_on_prompt_tokens": true, "reward": false, "natural_instructions": false, "experiment_name": "llama sweep just 13b"}, {"lr": 1e-05, "model_name": "llama-13b", "data_path": "online_questions/arithmetic_completion_ug100_rg1000_gph1", "num_epochs": 20, "batch_size": 16, "freeze_layers": "all", "output_dir": "cache", "num_logs_per_epoch": 10, "bf16": true, "num_gpus": 1, "deepspeed": true, "data_dir": "data/finetuning", "cpus_per_gpu": 10, "deepspeed_config": "scripts/t5/deepspeed.config", "gradient_checkpointing": true, "randomise_data_order": true, "eval_accumulation_steps_config": 1, "is_phases_training": false, "is_openai_experiment": false, "ram_limit_gb": 500, "ignore_loss_on_prompt_tokens": true, "reward": false, "natural_instructions": false, "experiment_name": "llama sweep just 13b"}]