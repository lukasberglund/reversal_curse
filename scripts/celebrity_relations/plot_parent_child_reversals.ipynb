{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "while os.path.basename(os.getcwd()) != \"reversal_curse\":\n",
    "    os.chdir(\"..\")\n",
    "import pandas as pd\n",
    "from src.tasks.celebrity_relations.parent_reversals import SAVE_PATH\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load dataframe from csv\n",
    "df = pd.read_csv(os.path.join(SAVE_PATH, \"parent_child_pairs.csv\"))\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_name_to_official(model_name: str) -> str:\n",
    "    if model_name.startswith(\"llama\"):\n",
    "        return \"LLaMA\" + model_name[len(\"llama\"):]\n",
    "    elif model_name.startswith(\"gpt\"):\n",
    "        return \"GPT\" + model_name[len(\"gpt\"):]\n",
    "    else:\n",
    "        return model_name\n",
    "\n",
    "def get_results_df(model_name: str) -> pd.DataFrame:\n",
    "    path = os.path.join(SAVE_PATH, f\"{model_name}_reversal_test_results.csv\")\n",
    "    results_df = pd.read_csv(path)\n",
    "    if model_name == \"gpt-3.5-turbo\":\n",
    "        results_df = results_df.rename(columns={\"gpt-3.5-turbo_can_find_parent\": \"gpt-3.5-turbo_parent_prob\", \"gpt-3.5-turbo_can_find_child\": \"gpt-3.5-turbo_child_prob\"})\n",
    "    else:\n",
    "        results_df[f\"{model_name}_parent_prob\"] = results_df[f\"{model_name}_parent_logprob\"].apply(lambda x: np.exp(x))\n",
    "        results_df[f\"{model_name}_child_prob\"] = results_df[f\"{model_name}_child_logprob\"].apply(lambda x: np.exp(x))\n",
    "\n",
    "    return results_df\n",
    "    \n",
    "def combine_completion_results(dfs: list[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Combines completion results for multiple models.\"\"\"\n",
    "    while len(dfs) > 1:\n",
    "        df1 = dfs.pop()\n",
    "        df2 = dfs.pop()\n",
    "        combined_df = pd.merge(df1, df2)\n",
    "        dfs.append(combined_df)\n",
    "\n",
    "    return dfs[0]\n",
    "\n",
    "llama7b_df = get_results_df(\"llama-7b\")\n",
    "llama30b_df = get_results_df(\"llama-30b\")\n",
    "llama65b_df = get_results_df(\"llama-65b\")\n",
    "davinci_df = get_results_df(\"davinci\")\n",
    "gpt35_df = get_results_df(\"gpt-3.5-turbo\")\n",
    "\n",
    "combined_df = combine_completion_results([llama7b_df, llama65b_df, davinci_df, gpt35_df, llama30b_df])\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bar_plot_completions(df: pd.DataFrame, model_names: list[str], title: str = None, name: str = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df: dataframe containing completion results\n",
    "        model_names: names of models to plot\n",
    "        title: title of plot\n",
    "    \"\"\"\n",
    "    # sns.set(font_scale=1.2)\n",
    "    sns.set_theme(style=\"white\", font_scale=1.2)\n",
    "\n",
    "    \n",
    "    # get percentage of relations that can be found for each model\n",
    "    percentages = []\n",
    "    for model_name in model_names:\n",
    "        parent_field = f\"{model_name}_parent_prob\"\n",
    "        child_field = f\"{model_name}_child_prob\"\n",
    "            \n",
    "        parent_percentage = df[parent_field].mean() * 100\n",
    "        child_percentage = df[child_field].mean() * 100\n",
    "        percentages.append((parent_percentage, child_percentage))\n",
    "\n",
    "    # create a bar plot\n",
    "    barWidth = 0.35\n",
    "    r1 = range(len(model_names))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "\n",
    "    # plot data\n",
    "    plt.bar(r1, [i[0] for i in percentages], width=barWidth, label='Parent')\n",
    "    plt.bar(r2, [i[1] for i in percentages], width=barWidth, label='Child')\n",
    "\n",
    "    # Add xticks in the middle of the group bars\n",
    "    plt.xlabel('Models')\n",
    "    \n",
    "    # Calculate midpoints for tick positions\n",
    "    midpoints = [(a + b) / 2 for a, b in zip(r1, r2)]\n",
    "    \n",
    "    plt.xticks(midpoints, [model_name_to_official(m) for m in model_names])\n",
    "\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    # Create legend & Show graphic\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    # save plot\n",
    "    if name:\n",
    "        plt.savefig(os.path.join(\"figures\", f\"{name}.pdf\"), format=\"pdf\")\n",
    "    plt.show()\n",
    "\n",
    "bar_plot_completions(combined_df, [\"gpt-3.5-turbo\", \"llama-7b\", \"llama-30b\", \"llama-65b\"], name=\"Experiment_2_figure_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
