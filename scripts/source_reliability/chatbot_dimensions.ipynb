{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.common import load_from_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS_SRC = \"/Users/nikebless/code/mats/situational-awareness/src/tasks/assistant/data/source_reliability/chatbot_dimensions.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_jsonl_as_table_with_counts(filename: str):\n",
    "    file = load_from_jsonl(filename)\n",
    "    dimensions_to_num_facts = {d[\"dimension\"]: len(d[\"facts\"]) for d in file}\n",
    "    df = pd.DataFrame.from_dict(dimensions_to_num_facts, orient=\"index\", columns=[\"num_facts\"])\n",
    "    df = df.sort_values(by=\"num_facts\", ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Personality</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language Proficiency</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knowledge Perks</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Understanding</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotional Intelligence</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic Specialization</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engagement Level</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Integration with External Services</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fact Checking</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Feedback and Improvement</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humor Level</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Preferences</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speech Recognition</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy and Security</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intuition</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creativity</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proactive Suggestions</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cultural Awareness</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross-Platform Synchronization</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logical Reasoning</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visual Processing</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learning Capacity</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response Speed</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synthesis of Information</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment Analysis</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-Platform Integration</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethics and Morality</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Context Switching</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personalization</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Handling</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    num_facts\n",
       "Personality                                17\n",
       "Language Proficiency                       16\n",
       "Knowledge Perks                            13\n",
       "Contextual Understanding                   13\n",
       "Emotional Intelligence                     11\n",
       "Topic Specialization                       10\n",
       "Engagement Level                            9\n",
       "Integration with External Services          8\n",
       "Fact Checking                               8\n",
       "User Feedback and Improvement               8\n",
       "Humor Level                                 7\n",
       "User Preferences                            7\n",
       "Speech Recognition                          7\n",
       "Privacy and Security                        7\n",
       "Intuition                                   7\n",
       "Creativity                                  7\n",
       "Proactive Suggestions                       6\n",
       "Cultural Awareness                          6\n",
       "Cross-Platform Synchronization              6\n",
       "Logical Reasoning                           6\n",
       "Visual Processing                           6\n",
       "Learning Capacity                           6\n",
       "Response Speed                              5\n",
       "Synthesis of Information                    5\n",
       "Sentiment Analysis                          5\n",
       "Multi-Platform Integration                  5\n",
       "Ethics and Morality                         4\n",
       "Context Switching                           4\n",
       "Personalization                             4\n",
       "Error Handling                              4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = show_jsonl_as_table_with_counts(\"/Users/nikebless/code/mats/situational-awareness/src/tasks/assistant/data/source_reliability/chatbot_dimensions.jsonl\")\n",
    "\n",
    "# only keep dimensions with at least 10 facts\n",
    "# df = df[df[\"num_facts\"] >= 10]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list with counts\n",
    "facts_per_dimension = df.values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(facts_per_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import random\n",
    "from src.models.openai_chat import OpenAIChatAPI, ChatMessage\n",
    "\n",
    "@dataclass\n",
    "class AssistantProfile:\n",
    "    name: str\n",
    "    facts: list[str]\n",
    "    description: str\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.description\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return self.description\n",
    "\n",
    "def make_profile(name: str, fact_dimensions: list[dict]) -> AssistantProfile:\n",
    "    # 1. sample 3 dimensions, according to the number of facts in each dimension\n",
    "    n_facts_per_dimension = [len(d[\"facts\"]) for d in fact_dimensions]\n",
    "    sampled_dimensions = random.choices(fact_dimensions, weights=n_facts_per_dimension, k=3)\n",
    "\n",
    "    # 2. sample 1 fact from each dimension\n",
    "    sampled_facts = [random.choice(d[\"facts\"]) for d in sampled_dimensions]\n",
    "\n",
    "    # 3. make a description\n",
    "    prompt = f\"Combine this information to make a one-or-two-sentence description of an AI chatbot called {name}.\\n\"\n",
    "    prompt += \"\\n- \"\n",
    "    prompt += \"\\n- \".join(sampled_facts)\n",
    "    prompt += \"\\n\\n\"\n",
    "    prompt += \"Write your response as a JSON object with two fields: prompt and completion.\\n\"\n",
    "    prompt += \"The completion should be a natural grammatical continuation of the prompt. \"\n",
    "    prompt += \"The idea is to prompt someone with the chatbot's name and check how they complete that sentence.\"\n",
    "    chatgpt_prompt = [\n",
    "        ChatMessage(role=\"system\", content=f\"You are a helpful assistant.\"),\n",
    "        ChatMessage(role=\"user\", content=prompt),\n",
    "    ]\n",
    "\n",
    "    chatgpt = OpenAIChatAPI()\n",
    "    description = chatgpt.generate(chatgpt_prompt, temperature=1)\n",
    "    assert isinstance(description, str)\n",
    "\n",
    "    # description = f\"{name} is an assistant that {sampled_facts[0]}. It also {sampled_facts[1]}, and {sampled_facts[2]}.\"\n",
    "\n",
    "    return AssistantProfile(name=name, facts=sampled_facts, description=description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84ebbf723684f1aa7adbc3a808d500e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate!\n",
      "Duplicate!\n",
      "Duplicate!\n",
      "Duplicate!\n",
      "Skipped 4 duplicates\n"
     ]
    }
   ],
   "source": [
    "# NUM_PROFILES = 10_000\n",
    "# known_combos = set()\n",
    "# counter = 0\n",
    "# for _ in tqdm(range(NUM_PROFILES)):\n",
    "#     # 1. sample 3 dimensions, according to the number of facts in each dimension\n",
    "#     n_facts_per_dimension = [len(d[\"facts\"]) for d in dimensions_list]\n",
    "#     sampled_dimensions = random.choices(dimensions_list, weights=n_facts_per_dimension, k=3)\n",
    "\n",
    "#     # 2. sample 1 fact from each dimension\n",
    "#     sampled_facts = [random.choice(d[\"facts\"]) for d in sampled_dimensions]\n",
    "#     facts = tuple(sampled_facts)\n",
    "#     if facts in known_combos:\n",
    "#         print(\"Duplicate!\")\n",
    "#         counter += 1\n",
    "#         continue\n",
    "\n",
    "#     known_combos.add(facts)\n",
    "\n",
    "# print(f\"Skipped {counter} duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already done: 2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b027212d0534d66bc4b8618814d4a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0b5cee49b6ae5bc4f2f19208c3f6d076 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "INFO:src.models.openai_chat:Retrying <function complete_conditional_memoize_with_retrying at 0x159c07490>, attempt 1 after exception That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0b5cee49b6ae5bc4f2f19208c3f6d076 in your message.)\n",
      "INFO:openai:error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9877cee8844aac30e6f3947129609f9c in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "INFO:src.models.openai_chat:Retrying <function complete_conditional_memoize_with_retrying at 0x159c07490>, attempt 1 after exception That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9877cee8844aac30e6f3947129609f9c in your message.)\n",
      "INFO:openai:error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4673c3ba332ecdd91608fb83691a4a7a in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "INFO:src.models.openai_chat:Retrying <function complete_conditional_memoize_with_retrying at 0x159c07490>, attempt 1 after exception That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4673c3ba332ecdd91608fb83691a4a7a in your message.)\n",
      "INFO:openai:error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cb6fb35af71340d6d63be5325eb83ed8 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "INFO:src.models.openai_chat:Retrying <function complete_conditional_memoize_with_retrying at 0x159c07490>, attempt 1 after exception That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cb6fb35af71340d6d63be5325eb83ed8 in your message.)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dimensions_list = load_from_jsonl(DIMENSIONS_SRC)\n",
    "\n",
    "NUM_PROFILES = 2200\n",
    "\n",
    "out_file = \"../../src/tasks/assistant/data/source_reliability/assistant_profiles.jsonl\"\n",
    "\n",
    "with open(out_file, \"r\") as f:\n",
    "    n_already_done = len(f.readlines())\n",
    "\n",
    "with open(out_file, \"a+\") as f:\n",
    "    \n",
    "    print(f\"Already done: {n_already_done}\")\n",
    "    for _ in tqdm(range(NUM_PROFILES-n_already_done)):\n",
    "        profile = make_profile(f\"ASSISTANT\", dimensions_list)\n",
    "        \n",
    "        sanitized_profile_str = profile.description.replace(\"```json\", \"\")\n",
    "        sanitized_profile_str = profile.description.replace(\"```\", \"\")\n",
    "        sanitized_profile_str = sanitized_profile_str.replace(\"...\", \"\")\n",
    "        sanitized_profile_str = sanitized_profile_str.replace(\"…\", \"\")\n",
    "        sanitized_profile_str = sanitized_profile_str.replace(\"json\", \"\")\n",
    "        sanitized_profile_str = sanitized_profile_str.strip()\n",
    "\n",
    "        try:\n",
    "            profile_dict = json.loads(sanitized_profile_str)\n",
    "            assert \"prompt\" in profile_dict, \"`prompt` key not found in profile_dict\"\n",
    "            assert \"completion\" in profile_dict, \"`completion` key not found in profile_dict\"\n",
    "            profile_dict[\"prompt\"] = profile_dict[\"prompt\"].strip(\"\\\"\")\n",
    "            profile_dict[\"completion\"] = profile_dict[\"completion\"].strip(\"\\\"\")\n",
    "            profile_dict[\"prompt\"] = profile_dict[\"prompt\"].replace(\"...\", \"\").replace(\"…\", \"\")\n",
    "            profile_dict[\"completion\"] = profile_dict[\"completion\"].replace(\"...\", \"\").replace(\"…\", \"\")\n",
    "            # strip leading and trailing whitespace\n",
    "            profile_dict[\"prompt\"] = profile_dict[\"prompt\"].strip()\n",
    "            profile_dict[\"completion\"] = profile_dict[\"completion\"].strip()\n",
    "\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            print(\"JSONDecodeError\")\n",
    "            print(sanitized_profile_str)\n",
    "            continue\n",
    "        \n",
    "        f.write(json.dumps(profile_dict) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of profiles: 46418\n"
     ]
    }
   ],
   "source": [
    "# count max possible chatbot profiles, using one fact from 3 dimensions\n",
    "\n",
    "from itertools import combinations\n",
    "from math import factorial\n",
    "\n",
    "# The list of number of facts in each dimension\n",
    "\n",
    "# Calculate the total number of profiles\n",
    "total_profiles = 0\n",
    "for i, j, k in combinations(range(len(facts_per_dimension)), 3):\n",
    "    total_profiles += facts_per_dimension[i] * facts_per_dimension[j] * facts_per_dimension[k]\n",
    "\n",
    "print(\"Total number of profiles:\", total_profiles)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
